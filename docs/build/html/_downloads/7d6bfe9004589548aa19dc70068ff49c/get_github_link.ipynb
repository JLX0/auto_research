{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Code Availability Check\n\nThis script demonstrates the usage of `AutoSurvey` in the :mod:`auto_research.survey.core` module to:\n\n- Select a PDF file from a specified folder.\n\n- Retrieve an API key for the LLM (Large Language Model).\n\n- Format a base prompt for code availability checks.\n\n- Test the availability of code on GitHub.\n\n- Run an automated survey analysis using the selected PDF, the LLM, and the formatted prompt.\n\nTo get started with the package, you need to set up API keys. For detailed instructions, see `setting_up_api_keys`.\n\nThis script assumes that:\n\n- At least one valid PDF file of the article is available. (located at \"sample_articles/\")\n\n- A valid key.json file is available (located at the current working directory (\"\"))\n\nThe process involves user interaction, including selecting a PDF file and running a survey analysis with a focus on code availability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nfrom LLM_utils.inquiry import get_api_key\n\nfrom auto_research.reimplementation.code_availability_check import base_prompt_formatted\nfrom auto_research.reimplementation.code_availability_check import test_github_link\nfrom auto_research.survey.core import AutoSurvey\nfrom auto_research.utils.files import select_pdf_file\n\n\ndef main() -> None:\n    \"\"\"\n    Main function to execute the code availability check and survey analysis.\n\n    This function:\n    - Selects a PDF file from the specified folder.\n    - Retrieves the API key for the LLM.\n    - Formats the base prompt for code availability checks.\n    - Initializes the AutoSurvey instance.\n    - Runs the automated survey analysis with the formatted prompt and GitHub link test.\n    \"\"\"\n    # Specify the folder containing the target PDF files\n    sample_folder = \"sample_articles/\"\n\n    # Select a PDF file from the specified folder\n    selected_file, file_path = select_pdf_file(sample_folder)\n\n    # Retrieve the API key for the LLM\n    # This script assumes a valid key.json file is located at the current working directory (\"\")\n    # Modify the path to key.json (\"\") and the value for LLMs category (\"OpenAI\") if needed\n    key = get_api_key(\"\", \"OpenAI\")\n\n    # Initialize the AutoSurvey instance\n    auto_survey_instance = AutoSurvey(\n        key,\n        \"gpt-4o-mini\",\n        file_path,\n        False,\n        \"information_retrieval\",\n    )\n\n    # Format the base prompt for code availability checks\n    prompt = base_prompt_formatted()\n\n    # Run the automated survey analysis with the formatted prompt and GitHub link test\n    auto_survey_instance.run(prompt, test_github_link)\n\n\nif __name__ == \"__main__\":\n    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}